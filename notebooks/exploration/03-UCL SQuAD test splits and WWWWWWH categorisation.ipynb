{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "jewish-advance",
   "metadata": {},
   "source": [
    "# UCL SQuAD test splits and WWWWWWH categorisation\n",
    "\n",
    "Exploring UCL's test split for SQuAD and occurance of WWWWWWH questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-hundred",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "nasty-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import datefinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sensitive-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-kingston",
   "metadata": {},
   "source": [
    "## Load SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arctic-armstrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/Users/stevengeorge/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7)\n",
      "Reusing dataset squad (/Users/stevengeorge/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7)\n"
     ]
    }
   ],
   "source": [
    "squad_train = load_dataset(\"squad\", split='train')\n",
    "squad_test = load_dataset(\"squad\", split='validation')  # Use validation set as test holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "changed-antenna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10570, 87599)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(squad_test), len(squad_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spanish-extreme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10767146451527468"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(squad_test) / (len(squad_test) + len(squad_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proud-latter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87599, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [515], 'text': ['Saint Bernad...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [188], 'text': ['a copper sta...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [279], 'text': ['the Main Bui...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'answer_start': [381], 'text': ['a Marian pla...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'answer_start': [92], 'text': ['a golden stat...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0  {'answer_start': [515], 'text': ['Saint Bernad...   \n",
       "1  {'answer_start': [188], 'text': ['a copper sta...   \n",
       "2  {'answer_start': [279], 'text': ['the Main Bui...   \n",
       "3  {'answer_start': [381], 'text': ['a Marian pla...   \n",
       "4  {'answer_start': [92], 'text': ['a golden stat...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                         id  \\\n",
       "0  5733be284776f41900661182   \n",
       "1  5733be284776f4190066117f   \n",
       "2  5733be284776f41900661180   \n",
       "3  5733be284776f41900661181   \n",
       "4  5733be284776f4190066117e   \n",
       "\n",
       "                                            question                     title  \n",
       "0  To whom did the Virgin Mary allegedly appear i...  University_of_Notre_Dame  \n",
       "1  What is in front of the Notre Dame Main Building?  University_of_Notre_Dame  \n",
       "2  The Basilica of the Sacred heart at Notre Dame...  University_of_Notre_Dame  \n",
       "3                  What is the Grotto at Notre Dame?  University_of_Notre_Dame  \n",
       "4  What sits on top of the Main Building at Notre...  University_of_Notre_Dame  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train_df = squad_train.data.to_pandas()\n",
    "print(squad_train_df.shape)\n",
    "squad_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "corrected-median",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10570, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [177, 177, 177], 'text': ['De...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [249, 249, 249], 'text': ['Ca...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [403, 355, 355], 'text': ['Sa...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'answer_start': [177, 177, 177], 'text': ['De...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ef</td>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'answer_start': [488, 488, 521], 'text': ['go...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502f0</td>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0  {'answer_start': [177, 177, 177], 'text': ['De...   \n",
       "1  {'answer_start': [249, 249, 249], 'text': ['Ca...   \n",
       "2  {'answer_start': [403, 355, 355], 'text': ['Sa...   \n",
       "3  {'answer_start': [177, 177, 177], 'text': ['De...   \n",
       "4  {'answer_start': [488, 488, 521], 'text': ['go...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Super Bowl 50 was an American football game to...   \n",
       "1  Super Bowl 50 was an American football game to...   \n",
       "2  Super Bowl 50 was an American football game to...   \n",
       "3  Super Bowl 50 was an American football game to...   \n",
       "4  Super Bowl 50 was an American football game to...   \n",
       "\n",
       "                         id  \\\n",
       "0  56be4db0acb8001400a502ec   \n",
       "1  56be4db0acb8001400a502ed   \n",
       "2  56be4db0acb8001400a502ee   \n",
       "3  56be4db0acb8001400a502ef   \n",
       "4  56be4db0acb8001400a502f0   \n",
       "\n",
       "                                            question          title  \n",
       "0  Which NFL team represented the AFC at Super Bo...  Super_Bowl_50  \n",
       "1  Which NFL team represented the NFC at Super Bo...  Super_Bowl_50  \n",
       "2                Where did Super Bowl 50 take place?  Super_Bowl_50  \n",
       "3                  Which NFL team won Super Bowl 50?  Super_Bowl_50  \n",
       "4  What color was used to emphasize the 50th anni...  Super_Bowl_50  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_test_df = squad_test.data.to_pandas()\n",
    "print(squad_test_df.shape)\n",
    "squad_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "identical-dispatch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': {'answer_start': [177, 177, 177],\n",
       "  'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos']},\n",
       " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       " 'id': '56be4db0acb8001400a502ec',\n",
       " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
       " 'title': 'Super_Bowl_50'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-beauty",
   "metadata": {},
   "source": [
    "## UCL splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "statewide-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_ucl_dev = pd.read_json('data/external/ucl_squad_dev_test_splits/split_dev_majority.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "frequent-breakdown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'Super_Bowl_50', 'paragraphs': [{'co...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'Warsaw', 'paragraphs': [{'context':...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'Teacher', 'paragraphs': [{'context'...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'Martin_Luther', 'paragraphs': [{'co...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'Sky_(United_Kingdom)', 'paragraphs'...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data version\n",
       "0  {'title': 'Super_Bowl_50', 'paragraphs': [{'co...        \n",
       "1  {'title': 'Warsaw', 'paragraphs': [{'context':...        \n",
       "2  {'title': 'Teacher', 'paragraphs': [{'context'...        \n",
       "3  {'title': 'Martin_Luther', 'paragraphs': [{'co...        \n",
       "4  {'title': 'Sky_(United_Kingdom)', 'paragraphs'...        "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(squad_ucl_dev.shape)\n",
    "squad_ucl_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "seasonal-depression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{''}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(squad_ucl_dev['version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "closed-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_ucl_dev.drop(columns='version', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "simplified-clothing",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Super_Bowl_50'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_ucl_dev.loc[0].item()['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "engaging-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_ucl_dev['title'] = squad_ucl_dev['data'].apply(lambda x: x['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dimensional-eugene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_ucl_dev.shape[0], squad_ucl_dev['title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "controlling-hungary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'Normans', 'paragraphs': [{'context'...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'Nikola_Tesla', 'paragraphs': [{'con...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'Computational_complexity_theory', '...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'Southern_California', 'paragraphs':...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'Victoria_(Australia)', 'paragraphs'...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data version\n",
       "0  {'title': 'Normans', 'paragraphs': [{'context'...        \n",
       "1  {'title': 'Nikola_Tesla', 'paragraphs': [{'con...        \n",
       "2  {'title': 'Computational_complexity_theory', '...        \n",
       "3  {'title': 'Southern_California', 'paragraphs':...        \n",
       "4  {'title': 'Victoria_(Australia)', 'paragraphs'...        "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_ucl_test = pd.read_json('data/external/ucl_squad_dev_test_splits/split_test_majority.json')\n",
    "print(squad_ucl_test.shape)\n",
    "squad_ucl_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "innocent-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_ucl_test.drop(columns='version', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "healthy-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_ucl_test['title'] = squad_ucl_test['data'].apply(lambda x: x['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "confidential-notification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 27)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_ucl_test.shape[0], squad_ucl_test['title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-controversy",
   "metadata": {},
   "source": [
    "Are titles in UCL dev and test splits overlapping or distinct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "infrared-reasoning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(squad_ucl_dev['title']).intersection(set(squad_ucl_test['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-amber",
   "metadata": {},
   "source": [
    "Distinct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-integrity",
   "metadata": {},
   "source": [
    "Check that no title in original dev set are not missing from UCL splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nervous-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>ucl_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Warsaw</td>\n",
       "      <td>ucl_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Teacher</td>\n",
       "      <td>ucl_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Martin_Luther</td>\n",
       "      <td>ucl_dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sky_(United_Kingdom)</td>\n",
       "      <td>ucl_dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title    split\n",
       "0         Super_Bowl_50  ucl_dev\n",
       "1                Warsaw  ucl_dev\n",
       "2               Teacher  ucl_dev\n",
       "3         Martin_Luther  ucl_dev\n",
       "4  Sky_(United_Kingdom)  ucl_dev"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucl_dev_titles = squad_ucl_dev.copy()[['title']]\n",
    "ucl_dev_titles['split'] = 'ucl_dev'\n",
    "\n",
    "ucl_test_titles = squad_ucl_test.copy()[['title']]\n",
    "ucl_test_titles['split'] = 'ucl_test'\n",
    "\n",
    "ucl_titles_df = ucl_dev_titles.append(ucl_test_titles)\n",
    "print(ucl_titles_df.shape)\n",
    "ucl_titles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "private-classics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>split</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [177, 177, 177], 'text': ['De...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>ucl_dev</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [249, 249, 249], 'text': ['Ca...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>ucl_dev</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [403, 355, 355], 'text': ['Sa...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>ucl_dev</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'answer_start': [177, 177, 177], 'text': ['De...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ef</td>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>ucl_dev</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'answer_start': [488, 488, 521], 'text': ['go...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502f0</td>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>ucl_dev</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0  {'answer_start': [177, 177, 177], 'text': ['De...   \n",
       "1  {'answer_start': [249, 249, 249], 'text': ['Ca...   \n",
       "2  {'answer_start': [403, 355, 355], 'text': ['Sa...   \n",
       "3  {'answer_start': [177, 177, 177], 'text': ['De...   \n",
       "4  {'answer_start': [488, 488, 521], 'text': ['go...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Super Bowl 50 was an American football game to...   \n",
       "1  Super Bowl 50 was an American football game to...   \n",
       "2  Super Bowl 50 was an American football game to...   \n",
       "3  Super Bowl 50 was an American football game to...   \n",
       "4  Super Bowl 50 was an American football game to...   \n",
       "\n",
       "                         id  \\\n",
       "0  56be4db0acb8001400a502ec   \n",
       "1  56be4db0acb8001400a502ed   \n",
       "2  56be4db0acb8001400a502ee   \n",
       "3  56be4db0acb8001400a502ef   \n",
       "4  56be4db0acb8001400a502f0   \n",
       "\n",
       "                                            question          title    split  \\\n",
       "0  Which NFL team represented the AFC at Super Bo...  Super_Bowl_50  ucl_dev   \n",
       "1  Which NFL team represented the NFC at Super Bo...  Super_Bowl_50  ucl_dev   \n",
       "2                Where did Super Bowl 50 take place?  Super_Bowl_50  ucl_dev   \n",
       "3                  Which NFL team won Super Bowl 50?  Super_Bowl_50  ucl_dev   \n",
       "4  What color was used to emphasize the 50th anni...  Super_Bowl_50  ucl_dev   \n",
       "\n",
       "  _merge  \n",
       "0   both  \n",
       "1   both  \n",
       "2   both  \n",
       "3   both  \n",
       "4   both  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df = squad_test_df.merge(ucl_titles_df, on='title', indicator=True, how='outer')\n",
    "check_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "affecting-yahoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          10570\n",
       "left_only         0\n",
       "right_only        0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ruled-albert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_test_df['title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-declaration",
   "metadata": {},
   "source": [
    "No titles missing in UCL splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-arctic",
   "metadata": {},
   "source": [
    "## Who, what, where, when, why, which, how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "endangered-colorado",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [515], 'text': ['Saint Bernad...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [188], 'text': ['a copper sta...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [279], 'text': ['the Main Bui...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'answer_start': [381], 'text': ['a Marian pla...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'answer_start': [92], 'text': ['a golden stat...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0  {'answer_start': [515], 'text': ['Saint Bernad...   \n",
       "1  {'answer_start': [188], 'text': ['a copper sta...   \n",
       "2  {'answer_start': [279], 'text': ['the Main Bui...   \n",
       "3  {'answer_start': [381], 'text': ['a Marian pla...   \n",
       "4  {'answer_start': [92], 'text': ['a golden stat...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                         id  \\\n",
       "0  5733be284776f41900661182   \n",
       "1  5733be284776f4190066117f   \n",
       "2  5733be284776f41900661180   \n",
       "3  5733be284776f41900661181   \n",
       "4  5733be284776f4190066117e   \n",
       "\n",
       "                                            question                     title  \n",
       "0  To whom did the Virgin Mary allegedly appear i...  University_of_Notre_Dame  \n",
       "1  What is in front of the Notre Dame Main Building?  University_of_Notre_Dame  \n",
       "2  The Basilica of the Sacred heart at Notre Dame...  University_of_Notre_Dame  \n",
       "3                  What is the Grotto at Notre Dame?  University_of_Notre_Dame  \n",
       "4  What sits on top of the Main Building at Notre...  University_of_Notre_Dame  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alone-revelation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>question_first_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [515], 'text': ['Saint Bernad...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [188], 'text': ['a copper sta...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [279], 'text': ['the Main Bui...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'answer_start': [381], 'text': ['a Marian pla...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'answer_start': [92], 'text': ['a golden stat...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0  {'answer_start': [515], 'text': ['Saint Bernad...   \n",
       "1  {'answer_start': [188], 'text': ['a copper sta...   \n",
       "2  {'answer_start': [279], 'text': ['the Main Bui...   \n",
       "3  {'answer_start': [381], 'text': ['a Marian pla...   \n",
       "4  {'answer_start': [92], 'text': ['a golden stat...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                         id  \\\n",
       "0  5733be284776f41900661182   \n",
       "1  5733be284776f4190066117f   \n",
       "2  5733be284776f41900661180   \n",
       "3  5733be284776f41900661181   \n",
       "4  5733be284776f4190066117e   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                      title question_first_word  \n",
       "0  University_of_Notre_Dame                  to  \n",
       "1  University_of_Notre_Dame                what  \n",
       "2  University_of_Notre_Dame                 the  \n",
       "3  University_of_Notre_Dame                what  \n",
       "4  University_of_Notre_Dame                what  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train_df['question_first_word'] = squad_train_df['question'].apply(lambda x: x.split()[0].lower())\n",
    "squad_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "banned-number",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2777"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train_df['question_first_word'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "miniature-shoulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what         37593\n",
       "who           8150\n",
       "how           8124\n",
       "when          5459\n",
       "in            4352\n",
       "which         4159\n",
       "where         3291\n",
       "the           2318\n",
       "why           1201\n",
       "on             590\n",
       "along          579\n",
       "during         443\n",
       "at             345\n",
       "a              318\n",
       "for            303\n",
       "to             291\n",
       "according      291\n",
       "from           282\n",
       "by             258\n",
       "after          250\n",
       "Name: question_first_word, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train_df['question_first_word'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "outer-terminology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "who      0.093038\n",
       "what     0.429149\n",
       "where    0.037569\n",
       "when     0.062318\n",
       "why      0.013710\n",
       "which    0.047478\n",
       "how      0.092741\n",
       "Name: question_first_word, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(squad_train_df['question_first_word'].value_counts() / squad_train_df.shape[0]).head(20)[['who', 'what', 'where', 'when', 'why', 'which', 'how']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-modem",
   "metadata": {},
   "source": [
    "SQuAD test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "polyphonic-conversation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>question_first_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [177, 177, 177], 'text': ['De...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>which</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [249, 249, 249], 'text': ['Ca...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>which</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [403, 355, 355], 'text': ['Sa...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>where</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'answer_start': [177, 177, 177], 'text': ['De...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502ef</td>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>which</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'answer_start': [488, 488, 521], 'text': ['go...</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>56be4db0acb8001400a502f0</td>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0  {'answer_start': [177, 177, 177], 'text': ['De...   \n",
       "1  {'answer_start': [249, 249, 249], 'text': ['Ca...   \n",
       "2  {'answer_start': [403, 355, 355], 'text': ['Sa...   \n",
       "3  {'answer_start': [177, 177, 177], 'text': ['De...   \n",
       "4  {'answer_start': [488, 488, 521], 'text': ['go...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Super Bowl 50 was an American football game to...   \n",
       "1  Super Bowl 50 was an American football game to...   \n",
       "2  Super Bowl 50 was an American football game to...   \n",
       "3  Super Bowl 50 was an American football game to...   \n",
       "4  Super Bowl 50 was an American football game to...   \n",
       "\n",
       "                         id  \\\n",
       "0  56be4db0acb8001400a502ec   \n",
       "1  56be4db0acb8001400a502ed   \n",
       "2  56be4db0acb8001400a502ee   \n",
       "3  56be4db0acb8001400a502ef   \n",
       "4  56be4db0acb8001400a502f0   \n",
       "\n",
       "                                            question          title  \\\n",
       "0  Which NFL team represented the AFC at Super Bo...  Super_Bowl_50   \n",
       "1  Which NFL team represented the NFC at Super Bo...  Super_Bowl_50   \n",
       "2                Where did Super Bowl 50 take place?  Super_Bowl_50   \n",
       "3                  Which NFL team won Super Bowl 50?  Super_Bowl_50   \n",
       "4  What color was used to emphasize the 50th anni...  Super_Bowl_50   \n",
       "\n",
       "  question_first_word  \n",
       "0               which  \n",
       "1               which  \n",
       "2               where  \n",
       "3               which  \n",
       "4                what  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_test_df['question_first_word'] = squad_test_df['question'].apply(lambda x: x.split()[0].lower())\n",
    "squad_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "spare-colony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_test_df['question_first_word'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "viral-stream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what       4749\n",
       "how        1090\n",
       "who        1059\n",
       "when        696\n",
       "which       454\n",
       "in          443\n",
       "where       433\n",
       "the         237\n",
       "why         151\n",
       "on           44\n",
       "to           43\n",
       "by           38\n",
       "along        36\n",
       "at           35\n",
       "whose        34\n",
       "if           32\n",
       "after        31\n",
       "besides      30\n",
       "other        29\n",
       "a            29\n",
       "Name: question_first_word, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_test_df['question_first_word'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "external-deadline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "who      0.100189\n",
       "what     0.449290\n",
       "where    0.040965\n",
       "when     0.065847\n",
       "why      0.014286\n",
       "which    0.042952\n",
       "how      0.103122\n",
       "Name: question_first_word, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(squad_test_df['question_first_word'].value_counts() / squad_test_df.shape[0]).head(20)[['who', 'what', 'where', 'when', 'why', 'which', 'how']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dated-cambodia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "who      0.093038\n",
       "what     0.429149\n",
       "where    0.037569\n",
       "when     0.062318\n",
       "why      0.013710\n",
       "which    0.047478\n",
       "how      0.092741\n",
       "Name: question_first_word, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(squad_train_df['question_first_word'].value_counts() / squad_train_df.shape[0]).head(20)[['who', 'what', 'where', 'when', 'why', 'which', 'how']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-thinking",
   "metadata": {},
   "source": [
    "Similar distribution of questions types in train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-algebra",
   "metadata": {},
   "source": [
    "Questions which may require a date as the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "closing-injury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When did the scholar project begin?\n",
      "When did was Myanmar ruled by the Taungoo Dynasty ?\n",
      "When did Kerry visit Nicaragua?\n",
      "When forming compound tenses in Spanish, what auxiliary is no longer used?\n",
      "When did the Parthian Empire rise to become the main power in Iran?\n",
      "When a specialized species resorts to foraging and eating other diets, it's like because it's primary food source is?\n",
      "When did black regain the right to vote?\n",
      "When did the German Jewry seek to reform Jewish belief?\n",
      "When did Rutherford introduce the new name for the Society?\n",
      "When did hostilities between Japan and the Soviet Union resum after six years of peace?\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "for qn in squad_train_df[squad_train_df['question_first_word'] == 'when'].sample(10)['question']:\n",
    "    print(qn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
