#!/bin/bash -l

#$ -cwd
#$ -S /bin/bash
#$ -l tmem=16G
#$ -t 1-1440
#$ -l h_rt=24:00:00
#$ -o /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/array.out
#$ -e /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/array.err
#$ -l gpu=true

hostname
date

# Activate conda environment
conda activate rclearn

export LANG="en_US.utf8"
export LANGUAGE="en_US:en"

cd /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn


test $SGE_TASK_ID -eq 1 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 2 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 3 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 4 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 5 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 6 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 7 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 8 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 9 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 10 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 11 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 12 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1.log 2>&1
test $SGE_TASK_ID -eq 13 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 14 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 15 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 16 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 17 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 18 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 19 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 20 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 21 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 22 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 23 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 24 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=2.log 2>&1
test $SGE_TASK_ID -eq 25 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 26 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 27 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 28 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 29 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 30 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 31 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 32 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 33 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 34 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 35 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 36 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=3.log 2>&1
test $SGE_TASK_ID -eq 37 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 38 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 39 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 40 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 41 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 42 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 43 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 44 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 45 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 46 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 47 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 48 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=4.log 2>&1
test $SGE_TASK_ID -eq 49 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 50 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 51 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 52 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 53 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 54 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 55 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 56 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 57 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 58 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 59 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 60 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=5.log 2>&1
test $SGE_TASK_ID -eq 61 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 62 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 63 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 64 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 65 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 66 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 67 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 68 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 69 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 70 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 71 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 72 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=6.log 2>&1
test $SGE_TASK_ID -eq 73 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 74 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-8 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 75 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 76 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 77 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-8 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 78 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 79 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 80 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-8 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 81 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 82 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 83 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-8 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 84 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=8.log 2>&1
test $SGE_TASK_ID -eq 85 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 86 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-10 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 87 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 88 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 89 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-10 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 90 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 91 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 92 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-10 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 93 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 94 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 95 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-10 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 96 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=10.log 2>&1
test $SGE_TASK_ID -eq 97 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 98 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-12 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 99 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 100 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 101 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-12 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 102 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 103 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 104 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-12 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 105 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 106 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 107 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-12 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 108 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=12.log 2>&1
test $SGE_TASK_ID -eq 109 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 110 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-14 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 111 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 112 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 113 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-14 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 114 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 115 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 116 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-14 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 117 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 118 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 119 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-14 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 120 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=14.log 2>&1
test $SGE_TASK_ID -eq 121 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 122 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-16 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 123 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 124 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 125 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-16 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 126 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 127 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 128 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-16 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 129 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 130 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 131 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-16 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 132 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=16.log 2>&1
test $SGE_TASK_ID -eq 133 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 134 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-20 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 135 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 136 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 137 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-20 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 138 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 139 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 140 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-20 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 141 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 142 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 143 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-20 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 144 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=20.log 2>&1
test $SGE_TASK_ID -eq 145 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 146 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-24 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 147 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 148 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 149 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-24 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 150 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 151 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 152 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-24 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 153 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 154 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 155 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-24 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 156 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=24.log 2>&1
test $SGE_TASK_ID -eq 157 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 158 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-28 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 159 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 160 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 161 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-28 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 162 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 163 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 164 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-28 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 165 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 166 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 167 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-28 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 168 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=28.log 2>&1
test $SGE_TASK_ID -eq 169 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 170 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-32 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 171 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 172 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 173 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-32 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 174 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 175 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 176 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-32 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 177 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 178 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 179 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-32 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 180 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=32.log 2>&1
test $SGE_TASK_ID -eq 181 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 182 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-36 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 183 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 184 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 185 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-36 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 186 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 187 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 188 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-36 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 189 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 190 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 191 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-36 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 192 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=36.log 2>&1
test $SGE_TASK_ID -eq 193 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 194 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-44 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 195 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 196 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 197 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-44 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 198 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 199 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 200 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-44 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 201 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 202 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 203 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-44 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 204 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=44.log 2>&1
test $SGE_TASK_ID -eq 205 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 206 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-52 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 207 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 208 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 209 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-52 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 210 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 211 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 212 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-52 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 213 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 214 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 215 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-52 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 216 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=52.log 2>&1
test $SGE_TASK_ID -eq 217 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 218 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-60 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 219 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 220 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 221 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-60 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 222 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 223 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 224 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-60 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 225 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 226 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 227 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-60 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 228 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=60.log 2>&1
test $SGE_TASK_ID -eq 229 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 230 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-68 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 231 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 232 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 233 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-68 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 234 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 235 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 236 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-68 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 237 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 238 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 239 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-68 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 240 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=68.log 2>&1
test $SGE_TASK_ID -eq 241 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 242 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-76 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 243 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 244 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 245 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-76 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 246 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 247 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 248 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-76 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 249 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 250 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 251 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-76 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 252 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=76.log 2>&1
test $SGE_TASK_ID -eq 253 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 254 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-92 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 255 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 256 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 257 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-92 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 258 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 259 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 260 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-92 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 261 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 262 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 263 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-92 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 264 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=92.log 2>&1
test $SGE_TASK_ID -eq 265 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 266 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-108 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 267 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 268 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 269 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-108 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 270 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 271 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 272 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-108 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 273 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 274 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 275 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-108 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 276 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=108.log 2>&1
test $SGE_TASK_ID -eq 277 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 278 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-124 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 279 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 280 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 281 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-124 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 282 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 283 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 284 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-124 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 285 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 286 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 287 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-124 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 288 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=124.log 2>&1
test $SGE_TASK_ID -eq 289 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 290 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-140 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 291 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 292 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 293 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-140 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 294 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 295 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 296 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-140 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 297 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 298 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 299 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-140 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 300 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=140.log 2>&1
test $SGE_TASK_ID -eq 301 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 302 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-156 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 303 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 304 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 305 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-156 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 306 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 307 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 308 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-156 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 309 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 310 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 311 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-156 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 312 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=156.log 2>&1
test $SGE_TASK_ID -eq 313 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 314 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-172 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 315 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 316 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 317 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-172 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 318 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 319 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 320 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-172 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 321 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 322 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 323 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-172 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 324 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=172.log 2>&1
test $SGE_TASK_ID -eq 325 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 326 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-188 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 327 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 328 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 329 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-188 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 330 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 331 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 332 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-188 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 333 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 334 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 335 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-188 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 336 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=188.log 2>&1
test $SGE_TASK_ID -eq 337 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 338 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-204 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 339 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 340 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 341 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-204 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 342 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 343 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 344 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-204 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 345 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 346 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 347 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-204 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 348 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=204.log 2>&1
test $SGE_TASK_ID -eq 349 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 350 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-220 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 351 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 352 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 353 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-220 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 354 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 355 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 356 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-220 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 357 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 358 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 359 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-220 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 360 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=220.log 2>&1
test $SGE_TASK_ID -eq 361 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 362 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-236 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 363 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 364 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 365 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-236 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 366 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 367 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 368 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-236 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 369 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 370 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 371 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-236 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 372 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=236.log 2>&1
test $SGE_TASK_ID -eq 373 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 374 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-252 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 375 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 376 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 377 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-252 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 378 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 379 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 380 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-252 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 381 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 382 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 383 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-252 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 384 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=252.log 2>&1
test $SGE_TASK_ID -eq 385 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 386 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-268 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 387 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 388 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 389 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-268 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 390 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 391 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 392 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-268 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 393 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 394 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 395 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-268 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 396 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=268.log 2>&1
test $SGE_TASK_ID -eq 397 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 398 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-284 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 399 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 400 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 401 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-284 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 402 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 403 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 404 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-284 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 405 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 406 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 407 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-284 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 408 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=284.log 2>&1
test $SGE_TASK_ID -eq 409 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 410 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-300 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 411 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 412 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 413 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-300 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 414 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 415 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 416 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-300 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 417 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 418 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 419 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-300 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 420 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=300.log 2>&1
test $SGE_TASK_ID -eq 421 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 422 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-316 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 423 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 424 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 425 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-316 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 426 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 427 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 428 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-316 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 429 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 430 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 431 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-316 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 432 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=316.log 2>&1
test $SGE_TASK_ID -eq 433 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 434 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-332 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 435 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 436 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 437 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-332 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 438 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 439 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 440 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-332 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 441 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 442 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 443 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-332 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 444 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=332.log 2>&1
test $SGE_TASK_ID -eq 445 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 446 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-348 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 447 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 448 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 449 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-348 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 450 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 451 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 452 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-348 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 453 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 454 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 455 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-348 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 456 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=348.log 2>&1
test $SGE_TASK_ID -eq 457 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 458 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-364 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 459 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 460 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 461 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-364 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 462 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 463 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 464 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-364 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 465 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 466 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 467 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-364 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 468 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=364.log 2>&1
test $SGE_TASK_ID -eq 469 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 470 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-380 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 471 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 472 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 473 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-380 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 474 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 475 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 476 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-380 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 477 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 478 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 479 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-380 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 480 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=380.log 2>&1
test $SGE_TASK_ID -eq 481 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 482 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-396 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 483 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 484 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 485 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-396 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 486 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 487 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 488 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-396 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 489 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 490 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 491 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-396 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 492 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=396.log 2>&1
test $SGE_TASK_ID -eq 493 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 494 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-428 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 495 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 496 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 497 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-428 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 498 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 499 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 500 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-428 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 501 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 502 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 503 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-428 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 504 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=428.log 2>&1
test $SGE_TASK_ID -eq 505 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 506 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-460 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 507 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 508 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 509 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-460 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 510 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 511 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 512 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-460 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 513 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 514 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 515 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-460 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 516 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=460.log 2>&1
test $SGE_TASK_ID -eq 517 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 518 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-492 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 519 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 520 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 521 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-492 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 522 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 523 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 524 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-492 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 525 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 526 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 527 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-492 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 528 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=492.log 2>&1
test $SGE_TASK_ID -eq 529 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 530 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-524 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 531 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 532 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 533 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-524 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 534 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 535 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 536 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-524 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 537 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 538 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 539 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-524 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 540 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=524.log 2>&1
test $SGE_TASK_ID -eq 541 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 542 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-556 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 543 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 544 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 545 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-556 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 546 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 547 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 548 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-556 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 549 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 550 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 551 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-556 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 552 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=556.log 2>&1
test $SGE_TASK_ID -eq 553 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 554 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-588 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 555 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 556 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 557 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-588 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 558 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 559 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 560 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-588 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 561 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 562 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 563 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-588 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 564 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=588.log 2>&1
test $SGE_TASK_ID -eq 565 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 566 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-620 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 567 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 568 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 569 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-620 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 570 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 571 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 572 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-620 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 573 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 574 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 575 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-620 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 576 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=620.log 2>&1
test $SGE_TASK_ID -eq 577 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 578 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-652 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 579 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 580 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 581 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-652 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 582 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 583 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 584 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-652 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 585 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 586 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 587 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-652 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 588 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=652.log 2>&1
test $SGE_TASK_ID -eq 589 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 590 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-684 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 591 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 592 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 593 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-684 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 594 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 595 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 596 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-684 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 597 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 598 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 599 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-684 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 600 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=684.log 2>&1
test $SGE_TASK_ID -eq 601 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 602 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-716 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 603 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 604 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 605 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-716 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 606 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 607 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 608 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-716 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 609 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 610 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 611 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-716 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 612 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=716.log 2>&1
test $SGE_TASK_ID -eq 613 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 614 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-748 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 615 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 616 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 617 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-748 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 618 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 619 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 620 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-748 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 621 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 622 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 623 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-748 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 624 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=748.log 2>&1
test $SGE_TASK_ID -eq 625 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 626 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-780 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 627 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 628 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 629 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-780 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 630 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 631 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 632 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-780 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 633 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 634 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 635 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-780 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 636 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=780.log 2>&1
test $SGE_TASK_ID -eq 637 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 638 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-812 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 639 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 640 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 641 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-812 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 642 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 643 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 644 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-812 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 645 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 646 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 647 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-812 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 648 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=812.log 2>&1
test $SGE_TASK_ID -eq 649 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 650 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-844 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 651 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 652 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 653 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-844 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 654 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 655 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 656 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-844 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 657 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 658 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 659 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-844 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 660 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=844.log 2>&1
test $SGE_TASK_ID -eq 661 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 662 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-876 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 663 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 664 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 665 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-876 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 666 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 667 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 668 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-876 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 669 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 670 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 671 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-876 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 672 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=876.log 2>&1
test $SGE_TASK_ID -eq 673 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 674 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-908 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 675 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 676 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 677 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-908 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 678 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 679 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 680 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-908 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 681 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 682 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 683 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-908 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 684 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=908.log 2>&1
test $SGE_TASK_ID -eq 685 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 686 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-940 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 687 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 688 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 689 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-940 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 690 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 691 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 692 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-940 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 693 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 694 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 695 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-940 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 696 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=940.log 2>&1
test $SGE_TASK_ID -eq 697 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 698 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-972 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 699 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 700 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 701 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-972 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 702 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 703 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 704 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-972 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 705 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 706 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 707 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-972 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 708 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=972.log 2>&1
test $SGE_TASK_ID -eq 709 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 710 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1004 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 711 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 712 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 713 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1004 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 714 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 715 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 716 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1004 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 717 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 718 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 719 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1004 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 720 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1004.log 2>&1
test $SGE_TASK_ID -eq 721 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 722 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1036 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 723 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 724 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 725 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1036 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 726 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 727 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 728 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1036 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 729 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 730 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 731 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1036 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 732 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1036.log 2>&1
test $SGE_TASK_ID -eq 733 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 734 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1100 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 735 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 736 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 737 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1100 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 738 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 739 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 740 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1100 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 741 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 742 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 743 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1100 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 744 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1100.log 2>&1
test $SGE_TASK_ID -eq 745 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 746 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1164 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 747 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 748 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 749 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1164 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 750 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 751 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 752 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1164 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 753 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 754 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 755 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1164 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 756 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1164.log 2>&1
test $SGE_TASK_ID -eq 757 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 758 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1228 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 759 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 760 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 761 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1228 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 762 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 763 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 764 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1228 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 765 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 766 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 767 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1228 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 768 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1228.log 2>&1
test $SGE_TASK_ID -eq 769 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 770 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1292 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 771 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 772 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 773 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1292 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 774 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 775 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 776 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1292 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 777 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 778 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 779 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1292 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 780 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1292.log 2>&1
test $SGE_TASK_ID -eq 781 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 782 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1356 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 783 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 784 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 785 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1356 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 786 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 787 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 788 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1356 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 789 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 790 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 791 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1356 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 792 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1356.log 2>&1
test $SGE_TASK_ID -eq 793 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 794 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1420 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 795 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 796 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 797 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1420 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 798 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 799 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 800 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1420 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 801 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 802 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 803 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1420 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 804 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1420.log 2>&1
test $SGE_TASK_ID -eq 805 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 806 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1484 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 807 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 808 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 809 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1484 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 810 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 811 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 812 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1484 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 813 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 814 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 815 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1484 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 816 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1484.log 2>&1
test $SGE_TASK_ID -eq 817 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 818 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1548 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 819 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 820 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 821 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1548 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 822 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 823 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 824 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1548 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 825 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 826 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 827 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1548 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 828 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1548.log 2>&1
test $SGE_TASK_ID -eq 829 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 830 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1612 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 831 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 832 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 833 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1612 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 834 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 835 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 836 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1612 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 837 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 838 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 839 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1612 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 840 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1612.log 2>&1
test $SGE_TASK_ID -eq 841 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 842 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1676 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 843 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 844 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 845 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1676 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 846 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 847 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 848 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1676 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 849 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 850 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 851 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1676 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 852 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1676.log 2>&1
test $SGE_TASK_ID -eq 853 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 854 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1804 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 855 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 856 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 857 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1804 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 858 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 859 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 860 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1804 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 861 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 862 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 863 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1804 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 864 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1804.log 2>&1
test $SGE_TASK_ID -eq 865 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 866 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1932 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 867 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 868 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 869 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1932 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 870 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 871 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 872 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1932 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 873 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 874 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 875 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-1932 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 876 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=1932.log 2>&1
test $SGE_TASK_ID -eq 877 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 878 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2060 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 879 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 880 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 881 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2060 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 882 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 883 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 884 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2060 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 885 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 886 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 887 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2060 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 888 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=2060.log 2>&1
test $SGE_TASK_ID -eq 889 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 890 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2188 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 891 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 892 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 893 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2188 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 894 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 895 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 896 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2188 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 897 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 898 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 899 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2188 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 900 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=2188.log 2>&1
test $SGE_TASK_ID -eq 901 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 902 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2316 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 903 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 904 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 905 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2316 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 906 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 907 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 908 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2316 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 909 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 910 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 911 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2316 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 912 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=2316.log 2>&1
test $SGE_TASK_ID -eq 913 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 914 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2444 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 915 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 916 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 917 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2444 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 918 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 919 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 920 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2444 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 921 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 922 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 923 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2444 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 924 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=2444.log 2>&1
test $SGE_TASK_ID -eq 925 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 926 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2572 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 927 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 928 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 929 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2572 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 930 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 931 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 932 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2572 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 933 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 934 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 935 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2572 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 936 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=2572.log 2>&1
test $SGE_TASK_ID -eq 937 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 938 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2700 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 939 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 940 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 941 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2700 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 942 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 943 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 944 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2700 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 945 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 946 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 947 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2700 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 948 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=2700.log 2>&1
test $SGE_TASK_ID -eq 949 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 950 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2828 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 951 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 952 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 953 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2828 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 954 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 955 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 956 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2828 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 957 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 958 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 959 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2828 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 960 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=2828.log 2>&1
test $SGE_TASK_ID -eq 961 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 962 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2956 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 963 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 964 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 965 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2956 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 966 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 967 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 968 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2956 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 969 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 970 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 971 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-2956 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 972 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=2956.log 2>&1
test $SGE_TASK_ID -eq 973 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 974 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3084 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 975 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 976 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 977 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3084 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 978 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 979 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 980 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3084 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 981 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 982 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 983 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3084 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 984 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=3084.log 2>&1
test $SGE_TASK_ID -eq 985 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 986 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3212 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 987 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 988 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 989 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3212 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 990 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 991 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 992 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3212 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 993 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 994 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 995 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3212 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 996 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=3212.log 2>&1
test $SGE_TASK_ID -eq 997 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 998 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3340 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 999 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 1000 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 1001 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3340 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 1002 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 1003 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 1004 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3340 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 1005 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 1006 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 1007 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3340 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 1008 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=3340.log 2>&1
test $SGE_TASK_ID -eq 1009 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1010 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3468 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1011 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1012 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1013 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3468 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1014 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1015 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1016 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3468 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1017 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1018 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1019 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3468 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1020 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=3468.log 2>&1
test $SGE_TASK_ID -eq 1021 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1022 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3596 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1023 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1024 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1025 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3596 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1026 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1027 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1028 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3596 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1029 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1030 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1031 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3596 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1032 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=3596.log 2>&1
test $SGE_TASK_ID -eq 1033 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1034 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3724 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1035 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1036 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1037 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3724 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1038 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1039 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1040 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3724 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1041 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1042 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1043 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3724 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1044 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=3724.log 2>&1
test $SGE_TASK_ID -eq 1045 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1046 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3852 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1047 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1048 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1049 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3852 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1050 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1051 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1052 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3852 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1053 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1054 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1055 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3852 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1056 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=3852.log 2>&1
test $SGE_TASK_ID -eq 1057 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1058 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3980 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1059 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1060 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1061 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3980 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1062 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1063 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1064 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3980 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1065 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1066 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1067 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-3980 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1068 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=3980.log 2>&1
test $SGE_TASK_ID -eq 1069 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1070 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4108 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1071 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1072 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1073 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4108 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1074 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1075 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1076 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4108 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1077 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1078 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1079 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4108 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1080 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=4108.log 2>&1
test $SGE_TASK_ID -eq 1081 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1082 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4236 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1083 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1084 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1085 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4236 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1086 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1087 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1088 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4236 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1089 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1090 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1091 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4236 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1092 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=4236.log 2>&1
test $SGE_TASK_ID -eq 1093 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1094 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4364 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1095 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1096 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1097 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4364 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1098 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1099 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1100 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4364 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1101 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1102 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1103 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4364 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1104 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=4364.log 2>&1
test $SGE_TASK_ID -eq 1105 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1106 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4492 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1107 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1108 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1109 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4492 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1110 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1111 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1112 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4492 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1113 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1114 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1115 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4492 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1116 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=4492.log 2>&1
test $SGE_TASK_ID -eq 1117 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1118 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4620 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1119 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1120 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1121 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4620 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1122 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1123 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1124 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4620 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1125 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1126 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1127 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4620 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1128 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=4620.log 2>&1
test $SGE_TASK_ID -eq 1129 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1130 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4748 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1131 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1132 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1133 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4748 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1134 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1135 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1136 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4748 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1137 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1138 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1139 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4748 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1140 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=4748.log 2>&1
test $SGE_TASK_ID -eq 1141 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1142 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4876 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1143 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1144 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1145 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4876 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1146 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1147 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1148 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4876 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1149 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1150 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1151 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-4876 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1152 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=4876.log 2>&1
test $SGE_TASK_ID -eq 1153 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1154 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5004 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1155 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1156 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1157 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5004 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1158 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1159 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1160 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5004 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1161 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1162 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1163 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5004 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1164 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=5004.log 2>&1
test $SGE_TASK_ID -eq 1165 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1166 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5132 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1167 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1168 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1169 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5132 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1170 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1171 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1172 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5132 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1173 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1174 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1175 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5132 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1176 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=5132.log 2>&1
test $SGE_TASK_ID -eq 1177 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1178 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5260 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1179 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1180 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1181 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5260 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1182 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1183 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1184 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5260 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1185 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1186 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1187 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5260 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1188 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=5260.log 2>&1
test $SGE_TASK_ID -eq 1189 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1190 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5388 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1191 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1192 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1193 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5388 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1194 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1195 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1196 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5388 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1197 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1198 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1199 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5388 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1200 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=5388.log 2>&1
test $SGE_TASK_ID -eq 1201 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1202 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5516 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1203 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1204 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1205 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5516 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1206 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1207 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1208 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5516 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1209 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1210 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1211 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5516 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1212 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=5516.log 2>&1
test $SGE_TASK_ID -eq 1213 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1214 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5644 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1215 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1216 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1217 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5644 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1218 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1219 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1220 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5644 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1221 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1222 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1223 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5644 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1224 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=5644.log 2>&1
test $SGE_TASK_ID -eq 1225 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1226 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5772 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1227 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1228 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1229 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5772 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1230 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1231 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1232 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5772 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1233 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1234 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1235 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5772 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1236 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=5772.log 2>&1
test $SGE_TASK_ID -eq 1237 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1238 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5900 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1239 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1240 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1241 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5900 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1242 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1243 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1244 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5900 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1245 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1246 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1247 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-5900 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1248 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=5900.log 2>&1
test $SGE_TASK_ID -eq 1249 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1250 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6028 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1251 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1252 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1253 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6028 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1254 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1255 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1256 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6028 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1257 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1258 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1259 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6028 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1260 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=6028.log 2>&1
test $SGE_TASK_ID -eq 1261 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1262 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6156 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1263 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1264 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1265 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6156 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1266 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1267 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1268 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6156 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1269 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1270 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1271 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6156 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1272 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=6156.log 2>&1
test $SGE_TASK_ID -eq 1273 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1274 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6284 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1275 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1276 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1277 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6284 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1278 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1279 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1280 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6284 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1281 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1282 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1283 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6284 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1284 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=6284.log 2>&1
test $SGE_TASK_ID -eq 1285 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1286 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6412 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1287 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1288 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1289 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6412 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1290 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1291 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1292 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6412 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1293 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1294 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1295 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6412 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1296 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=6412.log 2>&1
test $SGE_TASK_ID -eq 1297 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1298 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6540 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1299 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1300 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1301 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6540 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1302 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1303 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1304 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6540 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1305 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1306 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1307 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6540 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1308 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=6540.log 2>&1
test $SGE_TASK_ID -eq 1309 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1310 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6668 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1311 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1312 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1313 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6668 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1314 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1315 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1316 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6668 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1317 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1318 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1319 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6668 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1320 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=6668.log 2>&1
test $SGE_TASK_ID -eq 1321 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1322 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6796 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1323 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1324 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1325 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6796 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1326 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1327 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1328 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6796 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1329 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1330 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1331 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6796 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1332 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=6796.log 2>&1
test $SGE_TASK_ID -eq 1333 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1334 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6924 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1335 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1336 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1337 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6924 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1338 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1339 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1340 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6924 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1341 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1342 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1343 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-6924 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1344 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=6924.log 2>&1
test $SGE_TASK_ID -eq 1345 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1346 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7052 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1347 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1348 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1349 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7052 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1350 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1351 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1352 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7052 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1353 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1354 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1355 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7052 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1356 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=7052.log 2>&1
test $SGE_TASK_ID -eq 1357 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1358 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7180 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1359 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1360 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1361 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7180 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1362 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1363 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1364 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7180 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1365 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1366 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1367 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7180 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1368 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=7180.log 2>&1
test $SGE_TASK_ID -eq 1369 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1370 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7308 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1371 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1372 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1373 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7308 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1374 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1375 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1376 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7308 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1377 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1378 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1379 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7308 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1380 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=7308.log 2>&1
test $SGE_TASK_ID -eq 1381 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1382 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7436 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1383 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1384 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1385 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7436 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1386 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1387 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1388 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7436 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1389 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1390 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1391 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7436 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1392 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=7436.log 2>&1
test $SGE_TASK_ID -eq 1393 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1394 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7564 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1395 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1396 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1397 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7564 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1398 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1399 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1400 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7564 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1401 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1402 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1403 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7564 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1404 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=7564.log 2>&1
test $SGE_TASK_ID -eq 1405 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1406 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7692 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1407 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1408 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1409 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7692 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1410 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1411 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1412 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7692 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1413 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1414 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1415 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7692 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1416 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=7692.log 2>&1
test $SGE_TASK_ID -eq 1417 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1418 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7820 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1419 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1420 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1421 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7820 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1422 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1423 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1424 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7820 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1425 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1426 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1427 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7820 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1428 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=7820.log 2>&1
test $SGE_TASK_ID -eq 1429 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbidaf-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1430 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7948 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbidaf-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1431 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --dataset_name adversarial_qa --dataset_config_name dbidaf --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbidaf-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1432 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-dbert-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1433 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7948 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-dbert-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1434 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --dataset_name adversarial_qa --dataset_config_name dbert --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-dbert-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1435 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-droberta-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1436 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7948 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-droberta-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1437 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --dataset_name adversarial_qa --dataset_config_name droberta --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-droberta-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1438 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=27-squad-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1439 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28/checkpoint-7948 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=28-squad-checkpoint=7948.log 2>&1
test $SGE_TASK_ID -eq 1440 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --dataset_name squad --do_eval --per_device_eval_batch_size 128 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-squadv1-adversarialall-wu=100-lr=3e5-bs=32-msl=384-seed=29-squad-checkpoint=7948.log 2>&1

date
