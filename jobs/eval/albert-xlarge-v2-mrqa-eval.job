#!/bin/bash -l

#$ -cwd
#$ -S /bin/bash
#$ -l tmem=6G
#$ -t 1-2880
#$ -l h_rt=48:00:00
#$ -o /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/array_files
#$ -e /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/array_files
#$ -l gpu=true

hostname
date

# Activate conda environment
conda activate rclearn

export LANG="en_US.utf8"
export LANGUAGE="en_US:en"
export HF_HOME=/SAN/intelsys/rclearn/cache

cd /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn


test $SGE_TASK_ID -eq 1 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 3 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 4 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 5 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 6 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 7 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 8 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 9 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 10 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 11 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 12 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 13 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 14 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 15 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 16 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 17 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 18 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 19 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 20 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 21 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 22 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 23 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 24 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 25 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 26 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 27 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 28 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 29 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 30 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 31 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 32 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 33 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 34 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 35 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 36 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 37 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 38 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 39 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 40 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 41 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 42 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 43 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 44 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 45 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 46 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 47 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 48 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 49 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 50 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 51 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 52 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 53 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 54 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 55 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 56 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 57 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 58 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 59 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 60 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 61 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 62 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 63 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 64 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 65 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 66 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 67 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 68 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 69 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 70 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 71 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 72 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 73 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 74 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 75 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 76 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 77 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 78 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 79 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 80 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 81 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 82 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 83 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 84 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=8-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 85 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 86 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 87 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 88 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 89 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 90 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 91 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 92 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 93 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 94 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 95 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 96 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=10-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 97 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 98 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 99 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 100 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 101 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 102 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 103 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 104 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 105 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 106 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 107 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 108 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=12-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 109 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 110 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 111 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 112 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 113 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 114 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 115 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 116 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 117 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 118 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 119 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 120 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=14-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 121 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 122 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 123 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 124 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 125 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 126 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 127 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 128 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 129 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 130 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 131 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 132 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=16-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 133 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 134 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 135 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 136 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 137 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 138 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 139 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 140 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 141 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 142 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 143 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 144 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=20-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 145 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 146 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 147 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 148 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 149 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 150 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 151 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 152 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 153 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 154 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 155 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 156 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=24-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 157 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 158 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 159 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 160 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 161 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 162 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 163 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 164 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 165 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 166 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 167 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 168 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=28-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 169 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 170 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 171 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 172 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 173 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 174 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 175 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 176 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 177 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 178 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 179 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 180 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=32-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 181 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 182 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 183 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 184 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 185 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 186 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 187 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 188 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 189 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 190 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 191 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 192 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=36-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 193 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 194 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 195 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 196 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 197 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 198 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 199 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 200 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 201 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 202 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 203 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 204 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=44-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 205 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 206 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 207 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 208 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 209 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 210 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 211 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 212 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 213 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 214 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 215 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 216 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=52-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 217 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 218 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 219 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 220 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 221 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 222 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 223 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 224 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 225 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 226 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 227 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 228 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=60-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 229 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 230 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 231 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 232 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 233 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 234 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 235 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 236 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 237 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 238 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 239 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 240 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=68-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 241 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 242 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 243 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 244 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 245 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 246 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 247 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 248 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 249 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 250 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 251 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 252 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=76-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 253 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 254 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 255 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 256 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 257 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 258 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 259 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 260 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 261 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 262 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 263 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 264 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=92-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 265 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 266 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 267 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 268 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 269 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 270 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 271 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 272 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 273 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 274 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 275 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 276 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=108-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 277 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 278 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 279 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 280 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 281 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 282 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 283 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 284 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 285 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 286 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 287 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 288 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=124-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 289 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 290 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 291 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 292 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 293 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 294 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 295 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 296 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 297 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 298 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 299 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 300 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=140-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 301 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 302 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 303 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 304 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 305 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 306 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 307 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 308 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 309 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 310 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 311 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 312 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=156-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 313 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 314 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 315 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 316 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 317 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 318 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 319 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 320 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 321 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 322 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 323 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 324 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=172-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 325 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 326 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 327 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 328 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 329 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 330 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 331 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 332 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 333 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 334 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 335 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 336 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=188-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 337 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 338 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 339 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 340 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 341 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 342 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 343 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 344 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 345 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 346 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 347 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 348 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=204-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 349 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 350 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 351 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 352 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 353 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 354 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 355 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 356 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 357 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 358 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 359 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 360 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=220-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 361 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 362 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 363 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 364 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 365 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 366 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 367 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 368 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 369 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 370 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 371 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 372 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=236-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 373 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 374 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 375 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 376 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 377 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 378 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 379 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 380 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 381 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 382 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 383 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 384 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=252-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 385 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 386 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 387 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 388 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 389 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 390 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 391 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 392 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 393 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 394 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 395 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 396 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=268-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 397 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 398 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 399 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 400 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 401 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 402 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 403 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 404 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 405 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 406 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 407 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 408 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=284-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 409 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 410 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 411 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 412 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 413 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 414 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 415 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 416 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 417 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 418 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 419 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 420 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=300-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 421 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 422 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 423 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 424 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 425 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 426 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 427 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 428 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 429 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 430 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 431 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 432 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=316-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 433 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 434 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 435 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 436 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 437 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 438 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 439 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 440 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 441 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 442 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 443 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 444 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=332-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 445 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 446 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 447 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 448 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 449 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 450 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 451 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 452 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 453 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 454 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 455 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 456 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=348-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 457 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 458 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 459 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 460 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 461 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 462 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 463 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 464 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 465 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 466 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 467 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 468 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=364-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 469 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 470 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 471 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 472 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 473 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 474 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 475 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 476 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 477 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 478 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 479 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 480 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=380-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 481 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 482 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 483 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 484 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 485 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 486 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 487 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 488 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 489 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 490 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 491 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 492 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=396-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 493 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 494 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 495 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 496 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 497 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 498 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 499 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 500 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 501 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 502 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 503 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 504 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=428-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 505 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 506 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 507 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 508 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 509 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 510 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 511 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 512 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 513 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 514 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 515 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 516 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=460-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 517 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 518 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 519 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 520 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 521 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 522 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 523 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 524 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 525 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 526 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 527 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 528 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=492-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 529 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 530 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 531 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 532 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 533 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 534 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 535 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 536 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 537 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 538 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 539 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 540 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=524-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 541 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 542 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 543 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 544 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 545 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 546 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 547 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 548 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 549 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 550 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 551 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 552 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=556-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 553 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 554 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 555 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 556 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 557 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 558 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 559 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 560 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 561 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 562 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 563 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 564 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=588-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 565 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 566 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 567 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 568 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 569 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 570 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 571 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 572 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 573 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 574 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 575 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 576 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=620-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 577 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 578 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 579 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 580 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 581 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 582 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 583 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 584 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 585 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 586 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 587 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 588 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=652-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 589 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 590 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 591 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 592 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 593 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 594 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 595 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 596 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 597 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 598 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 599 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 600 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=684-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 601 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 602 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 603 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 604 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 605 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 606 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 607 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 608 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 609 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 610 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 611 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 612 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=716-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 613 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 614 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 615 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 616 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 617 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 618 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 619 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 620 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 621 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 622 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 623 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 624 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=748-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 625 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 626 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 627 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 628 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 629 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 630 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 631 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 632 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 633 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 634 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 635 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 636 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=780-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 637 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 638 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 639 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 640 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 641 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 642 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 643 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 644 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 645 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 646 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 647 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 648 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=812-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 649 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 650 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 651 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 652 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 653 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 654 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 655 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 656 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 657 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 658 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 659 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 660 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=844-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 661 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 662 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 663 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 664 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 665 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 666 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 667 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 668 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 669 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 670 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 671 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 672 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=876-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 673 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 674 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 675 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 676 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 677 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 678 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 679 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 680 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 681 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 682 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 683 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 684 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=908-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 685 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 686 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 687 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 688 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 689 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 690 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 691 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 692 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 693 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 694 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 695 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 696 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=940-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 697 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 698 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 699 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 700 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 701 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 702 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 703 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 704 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 705 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 706 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 707 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 708 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=972-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 709 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 710 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 711 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 712 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 713 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 714 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 715 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 716 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 717 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 718 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 719 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 720 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1004-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 721 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 722 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 723 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 724 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 725 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 726 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 727 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 728 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 729 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 730 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 731 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 732 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1036-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 733 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 734 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 735 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 736 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 737 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 738 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 739 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 740 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 741 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 742 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 743 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 744 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1100-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 745 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 746 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 747 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 748 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 749 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 750 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 751 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 752 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 753 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 754 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 755 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 756 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1164-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 757 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 758 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 759 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 760 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 761 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 762 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 763 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 764 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 765 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 766 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 767 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 768 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1228-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 769 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 770 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 771 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 772 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 773 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 774 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 775 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 776 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 777 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 778 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 779 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 780 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1292-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 781 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 782 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 783 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 784 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 785 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 786 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 787 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 788 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 789 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 790 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 791 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 792 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1356-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 793 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 794 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 795 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 796 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 797 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 798 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 799 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 800 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 801 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 802 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 803 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 804 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1420-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 805 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 806 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 807 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 808 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 809 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 810 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 811 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 812 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 813 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 814 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 815 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 816 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1484-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 817 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 818 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 819 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 820 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 821 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 822 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 823 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 824 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 825 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 826 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 827 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 828 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1548-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 829 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 830 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 831 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 832 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 833 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 834 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 835 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 836 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 837 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 838 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 839 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 840 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1612-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 841 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 842 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 843 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 844 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 845 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 846 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 847 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 848 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 849 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 850 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 851 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 852 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1676-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 853 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 854 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 855 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 856 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 857 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 858 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 859 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 860 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 861 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 862 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 863 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 864 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1804-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 865 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 866 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 867 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 868 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 869 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 870 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 871 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 872 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 873 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 874 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 875 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 876 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=1932-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 877 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 878 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 879 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 880 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 881 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 882 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 883 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 884 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 885 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 886 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 887 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 888 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2060-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 889 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 890 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 891 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 892 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 893 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 894 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 895 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 896 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 897 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 898 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 899 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 900 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2188-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 901 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 902 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 903 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 904 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 905 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 906 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 907 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 908 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 909 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 910 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 911 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 912 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2316-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 913 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 914 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 915 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 916 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 917 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 918 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 919 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 920 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 921 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 922 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 923 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 924 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2444-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 925 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 926 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 927 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 928 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 929 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 930 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 931 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 932 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 933 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 934 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 935 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 936 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2572-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 937 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 938 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 939 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 940 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 941 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 942 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 943 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 944 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 945 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 946 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 947 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 948 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2700-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 949 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 950 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 951 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 952 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 953 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 954 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 955 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 956 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 957 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 958 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 959 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 960 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2828-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 961 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 962 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 963 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 964 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 965 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 966 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 967 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 968 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 969 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 970 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 971 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 972 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=2956-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 973 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 974 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 975 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 976 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 977 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 978 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 979 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 980 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 981 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 982 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 983 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 984 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3084-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 985 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 986 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 987 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 988 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 989 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 990 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 991 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 992 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 993 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 994 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 995 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 996 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3212-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 997 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 998 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 999 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1000 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1001 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1002 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1003 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1004 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1005 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1006 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1007 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1008 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3340-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1009 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1010 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1011 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1012 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1013 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1014 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1015 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1016 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1017 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1018 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1019 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1020 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3468-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1021 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1022 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1023 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1024 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1025 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1026 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1027 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1028 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1029 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1030 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1031 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1032 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3596-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1033 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1034 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1035 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1036 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1037 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1038 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1039 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1040 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1041 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1042 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1043 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1044 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3724-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1045 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1046 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1047 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1048 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1049 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1050 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1051 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1052 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1053 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1054 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1055 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1056 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3852-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1057 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1058 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1059 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1060 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1061 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1062 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1063 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1064 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1065 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1066 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1067 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1068 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=3980-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1069 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1070 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1071 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1072 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1073 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1074 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1075 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1076 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1077 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1078 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1079 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1080 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4108-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1081 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1082 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1083 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1084 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1085 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1086 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1087 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1088 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1089 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1090 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1091 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1092 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4236-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1093 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1094 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1095 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1096 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1097 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1098 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1099 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1100 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1101 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1102 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1103 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1104 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4364-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1105 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1106 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1107 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1108 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1109 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1110 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1111 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1112 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1113 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1114 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1115 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1116 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4492-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1117 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1118 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1119 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1120 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1121 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1122 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1123 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1124 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1125 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1126 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1127 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1128 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4620-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1129 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1130 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1131 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1132 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1133 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1134 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1135 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1136 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1137 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1138 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1139 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1140 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4748-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1141 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1142 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1143 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1144 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1145 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1146 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1147 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1148 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1149 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1150 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1151 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1152 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=4876-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1153 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1154 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1155 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1156 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1157 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1158 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1159 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1160 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1161 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1162 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1163 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1164 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5004-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1165 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1166 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1167 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1168 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1169 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1170 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1171 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1172 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1173 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1174 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1175 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1176 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5132-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1177 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1178 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1179 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1180 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1181 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1182 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1183 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1184 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1185 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1186 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1187 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1188 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5260-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1189 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1190 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1191 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1192 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1193 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1194 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1195 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1196 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1197 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1198 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1199 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1200 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5388-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1201 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1202 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1203 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1204 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1205 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1206 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1207 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1208 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1209 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1210 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1211 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1212 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5516-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1213 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1214 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1215 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1216 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1217 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1218 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1219 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1220 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1221 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1222 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1223 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1224 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5644-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1225 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1226 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1227 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1228 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1229 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1230 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1231 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1232 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1233 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1234 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1235 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1236 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5772-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1237 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1238 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1239 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1240 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1241 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1242 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1243 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1244 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1245 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1246 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1247 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1248 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=5900-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1249 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1250 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1251 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1252 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1253 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1254 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1255 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1256 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1257 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1258 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1259 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1260 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6028-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1261 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1262 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1263 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1264 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1265 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1266 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1267 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1268 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1269 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1270 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1271 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1272 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6156-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1273 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1274 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1275 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1276 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1277 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1278 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1279 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1280 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1281 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1282 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1283 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1284 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6284-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1285 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1286 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1287 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1288 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1289 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1290 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1291 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1292 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1293 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1294 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1295 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1296 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6412-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1297 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1298 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1299 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1300 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1301 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1302 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1303 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1304 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1305 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1306 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1307 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1308 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6540-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1309 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1310 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1311 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1312 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1313 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1314 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1315 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1316 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1317 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1318 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1319 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1320 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6668-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1321 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1322 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1323 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1324 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1325 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1326 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1327 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1328 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1329 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1330 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1331 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1332 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6796-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1333 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1334 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1335 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1336 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1337 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1338 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1339 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1340 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1341 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1342 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1343 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1344 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=6924-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1345 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1346 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1347 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1348 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1349 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1350 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1351 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1352 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1353 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1354 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1355 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1356 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7052-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1357 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1358 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1359 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1360 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1361 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1362 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1363 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1364 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1365 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1366 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1367 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1368 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7180-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1369 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1370 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1371 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1372 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1373 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1374 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1375 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1376 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1377 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1378 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1379 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1380 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7308-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1381 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1382 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1383 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1384 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1385 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1386 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1387 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1388 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1389 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1390 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1391 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1392 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7436-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1393 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1394 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1395 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1396 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1397 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1398 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1399 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1400 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1401 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1402 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1403 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1404 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7564-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1405 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1406 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1407 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1408 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1409 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1410 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1411 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1412 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1413 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1414 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1415 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1416 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7692-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1417 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1418 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1419 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1420 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1421 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1422 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1423 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1424 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1425 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1426 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1427 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1428 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7820-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1429 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=hotpotqa/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1430 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=naturalquestions/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1431 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=newsqa/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1432 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=searchqa/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1433 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=squad/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1434 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=triviaqa/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1435 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=bioasq/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1436 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=drop/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1437 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=duorc/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1438 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=race/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1439 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=relationextraction/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1440 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-dataset=textbookqa/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=27-checkpoint=7948-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1441 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1442 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1443 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1444 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1445 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1446 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1447 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1448 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1449 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1450 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1451 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1452 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1453 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1454 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1455 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1456 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1457 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1458 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1459 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1460 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1461 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1462 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1463 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1464 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-2 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1465 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1466 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1467 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1468 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1469 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1470 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1471 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1472 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1473 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1474 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1475 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1476 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-3 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1477 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1478 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1479 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1480 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1481 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1482 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1483 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1484 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1485 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1486 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1487 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1488 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-4 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1489 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1490 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1491 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1492 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1493 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1494 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1495 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1496 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1497 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1498 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1499 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1500 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-5 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1501 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1502 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1503 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1504 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1505 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1506 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1507 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1508 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1509 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1510 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1511 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1512 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-6 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1513 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1514 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1515 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1516 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1517 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1518 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1519 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1520 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1521 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1522 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1523 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1524 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-8 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-8 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=8-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1525 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1526 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1527 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1528 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1529 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1530 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1531 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1532 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1533 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1534 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1535 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1536 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-10 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-10 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=10-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1537 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1538 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1539 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1540 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1541 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1542 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1543 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1544 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1545 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1546 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1547 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1548 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-12 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-12 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=12-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1549 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1550 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1551 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1552 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1553 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1554 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1555 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1556 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1557 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1558 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1559 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1560 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-14 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-14 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=14-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1561 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1562 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1563 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1564 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1565 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1566 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1567 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1568 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1569 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1570 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1571 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1572 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-16 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-16 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=16-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1573 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1574 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1575 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1576 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1577 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1578 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1579 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1580 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1581 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1582 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1583 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1584 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-20 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-20 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=20-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1585 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1586 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1587 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1588 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1589 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1590 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1591 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1592 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1593 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1594 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1595 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1596 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-24 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-24 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=24-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1597 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1598 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1599 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1600 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1601 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1602 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1603 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1604 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1605 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1606 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1607 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1608 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-28 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-28 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=28-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1609 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1610 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1611 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1612 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1613 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1614 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1615 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1616 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1617 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1618 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1619 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1620 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-32 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-32 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=32-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1621 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1622 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1623 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1624 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1625 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1626 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1627 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1628 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1629 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1630 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1631 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1632 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-36 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-36 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=36-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1633 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1634 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1635 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1636 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1637 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1638 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1639 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1640 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1641 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1642 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1643 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1644 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-44 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-44 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=44-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1645 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1646 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1647 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1648 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1649 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1650 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1651 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1652 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1653 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1654 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1655 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1656 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-52 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-52 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=52-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1657 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1658 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1659 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1660 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1661 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1662 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1663 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1664 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1665 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1666 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1667 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1668 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-60 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-60 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=60-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1669 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1670 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1671 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1672 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1673 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1674 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1675 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1676 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1677 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1678 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1679 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1680 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-68 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-68 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=68-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1681 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1682 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1683 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1684 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1685 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1686 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1687 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1688 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1689 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1690 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1691 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1692 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-76 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-76 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=76-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1693 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1694 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1695 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1696 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1697 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1698 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1699 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1700 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1701 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1702 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1703 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1704 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-92 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-92 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=92-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1705 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1706 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1707 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1708 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1709 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1710 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1711 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1712 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1713 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1714 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1715 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1716 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=108-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1717 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1718 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1719 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1720 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1721 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1722 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1723 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1724 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1725 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1726 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1727 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1728 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-124 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-124 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=124-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1729 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1730 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1731 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1732 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1733 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1734 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1735 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1736 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1737 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1738 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1739 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1740 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-140 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-140 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=140-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1741 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1742 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1743 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1744 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1745 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1746 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1747 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1748 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1749 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1750 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1751 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1752 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=156-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1753 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1754 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1755 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1756 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1757 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1758 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1759 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1760 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1761 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1762 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1763 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1764 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-172 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-172 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=172-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1765 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1766 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1767 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1768 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1769 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1770 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1771 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1772 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1773 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1774 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1775 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1776 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=188-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1777 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1778 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1779 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1780 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1781 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1782 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1783 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1784 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1785 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1786 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1787 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1788 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-204 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-204 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=204-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1789 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1790 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1791 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1792 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1793 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1794 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1795 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1796 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1797 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1798 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1799 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1800 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-220 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-220 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=220-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1801 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1802 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1803 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1804 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1805 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1806 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1807 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1808 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1809 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1810 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1811 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1812 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=236-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1813 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1814 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1815 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1816 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1817 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1818 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1819 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1820 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1821 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1822 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1823 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1824 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-252 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-252 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=252-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1825 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1826 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1827 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1828 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1829 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1830 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1831 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1832 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1833 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1834 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1835 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1836 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-268 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-268 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=268-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1837 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1838 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1839 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1840 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1841 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1842 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1843 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1844 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1845 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1846 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1847 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1848 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=284-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1849 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1850 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1851 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1852 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1853 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1854 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1855 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1856 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1857 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1858 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1859 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1860 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-300 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-300 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=300-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1861 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1862 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1863 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1864 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1865 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1866 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1867 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1868 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1869 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1870 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1871 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1872 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=316-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1873 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1874 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1875 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1876 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1877 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1878 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1879 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1880 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1881 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1882 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1883 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1884 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-332 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-332 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=332-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1885 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1886 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1887 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1888 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1889 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1890 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1891 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1892 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1893 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1894 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1895 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1896 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-348 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-348 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=348-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1897 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1898 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1899 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1900 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1901 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1902 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1903 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1904 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1905 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1906 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1907 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1908 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=364-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1909 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1910 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1911 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1912 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1913 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1914 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1915 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1916 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1917 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1918 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1919 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1920 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-380 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-380 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=380-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1921 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1922 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1923 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1924 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1925 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1926 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1927 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1928 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1929 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1930 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1931 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1932 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-396 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-396 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=396-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1933 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1934 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1935 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1936 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1937 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1938 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1939 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1940 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1941 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1942 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1943 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1944 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-428 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-428 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=428-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1945 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1946 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1947 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1948 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1949 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1950 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1951 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1952 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1953 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1954 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1955 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1956 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-460 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-460 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=460-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1957 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1958 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1959 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1960 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1961 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1962 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1963 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1964 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1965 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1966 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1967 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1968 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=492-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1969 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1970 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1971 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1972 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1973 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1974 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1975 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1976 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1977 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1978 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1979 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1980 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-524 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-524 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=524-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1981 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1982 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1983 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1984 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1985 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1986 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1987 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 1988 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 1989 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 1990 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 1991 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 1992 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-556 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-556 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=556-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 1993 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 1994 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 1995 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 1996 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 1997 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 1998 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 1999 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2000 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2001 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2002 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2003 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2004 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-588 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-588 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=588-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2005 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2006 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2007 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2008 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2009 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2010 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2011 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2012 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2013 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2014 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2015 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2016 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=620-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2017 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2018 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2019 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2020 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2021 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2022 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2023 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2024 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2025 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2026 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2027 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2028 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-652 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-652 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=652-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2029 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2030 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2031 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2032 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2033 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2034 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2035 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2036 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2037 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2038 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2039 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2040 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-684 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-684 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=684-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2041 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2042 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2043 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2044 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2045 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2046 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2047 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2048 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2049 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2050 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2051 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2052 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-716 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-716 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=716-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2053 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2054 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2055 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2056 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2057 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2058 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2059 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2060 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2061 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2062 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2063 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2064 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=748-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2065 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2066 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2067 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2068 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2069 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2070 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2071 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2072 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2073 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2074 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2075 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2076 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-780 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-780 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=780-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2077 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2078 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2079 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2080 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2081 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2082 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2083 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2084 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2085 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2086 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2087 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2088 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-812 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-812 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=812-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2089 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2090 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2091 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2092 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2093 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2094 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2095 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2096 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2097 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2098 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2099 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2100 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-844 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-844 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=844-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2101 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2102 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2103 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2104 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2105 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2106 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2107 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2108 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2109 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2110 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2111 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2112 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=876-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2113 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2114 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2115 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2116 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2117 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2118 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2119 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2120 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2121 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2122 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2123 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2124 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-908 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-908 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=908-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2125 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2126 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2127 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2128 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2129 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2130 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2131 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2132 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2133 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2134 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2135 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2136 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-940 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-940 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=940-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2137 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2138 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2139 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2140 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2141 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2142 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2143 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2144 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2145 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2146 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2147 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2148 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-972 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-972 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=972-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2149 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2150 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2151 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2152 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2153 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2154 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2155 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2156 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2157 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2158 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2159 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2160 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1004-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2161 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2162 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2163 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2164 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2165 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2166 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2167 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2168 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2169 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2170 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2171 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2172 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1036 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1036 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1036-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2173 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2174 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2175 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2176 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2177 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2178 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2179 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2180 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2181 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2182 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2183 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2184 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1100 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1100 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1100-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2185 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2186 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2187 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2188 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2189 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2190 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2191 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2192 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2193 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2194 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2195 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2196 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1164 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1164 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1164-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2197 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2198 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2199 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2200 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2201 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2202 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2203 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2204 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2205 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2206 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2207 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2208 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1228 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1228 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1228-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2209 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2210 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2211 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2212 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2213 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2214 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2215 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2216 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2217 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2218 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2219 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2220 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1292 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1292 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1292-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2221 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2222 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2223 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2224 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2225 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2226 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2227 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2228 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2229 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2230 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2231 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2232 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1356 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1356 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1356-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2233 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2234 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2235 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2236 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2237 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2238 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2239 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2240 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2241 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2242 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2243 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2244 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1420 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1420 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1420-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2245 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2246 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2247 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2248 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2249 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2250 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2251 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2252 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2253 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2254 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2255 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2256 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1484 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1484 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1484-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2257 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2258 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2259 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2260 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2261 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2262 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2263 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2264 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2265 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2266 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2267 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2268 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1548 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1548 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1548-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2269 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2270 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2271 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2272 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2273 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2274 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2275 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2276 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2277 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2278 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2279 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2280 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1612 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1612 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1612-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2281 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2282 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2283 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2284 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2285 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2286 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2287 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2288 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2289 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2290 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2291 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2292 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1676 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1676 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1676-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2293 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2294 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2295 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2296 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2297 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2298 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2299 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2300 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2301 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2302 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2303 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2304 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1804 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1804 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1804-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2305 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2306 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2307 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2308 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2309 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2310 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2311 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2312 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2313 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2314 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2315 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2316 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-1932 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-1932 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=1932-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2317 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2318 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2319 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2320 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2321 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2322 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2323 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2324 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2325 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2326 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2327 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2328 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2060 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-2060 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2060-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2329 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2330 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2331 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2332 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2333 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2334 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2335 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2336 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2337 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2338 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2339 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2340 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2188 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-2188 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2188-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2341 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2342 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2343 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2344 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2345 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2346 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2347 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2348 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2349 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2350 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2351 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2352 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2316 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-2316 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2316-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2353 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2354 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2355 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2356 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2357 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2358 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2359 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2360 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2361 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2362 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2363 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2364 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2444 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-2444 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2444-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2365 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2366 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2367 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2368 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2369 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2370 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2371 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2372 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2373 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2374 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2375 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2376 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2572 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-2572 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2572-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2377 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2378 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2379 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2380 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2381 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2382 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2383 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2384 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2385 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2386 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2387 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2388 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2700 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-2700 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2700-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2389 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2390 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2391 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2392 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2393 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2394 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2395 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2396 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2397 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2398 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2399 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2400 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2828 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-2828 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2828-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2401 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2402 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2403 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2404 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2405 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2406 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2407 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2408 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2409 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2410 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2411 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2412 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-2956 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-2956 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=2956-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2413 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2414 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2415 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2416 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2417 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2418 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2419 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2420 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2421 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2422 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2423 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2424 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3084 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-3084 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3084-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2425 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2426 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2427 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2428 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2429 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2430 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2431 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2432 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2433 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2434 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2435 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2436 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3212 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-3212 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3212-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2437 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2438 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2439 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2440 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2441 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2442 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2443 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2444 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2445 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2446 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2447 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2448 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3340 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-3340 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3340-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2449 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2450 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2451 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2452 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2453 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2454 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2455 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2456 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2457 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2458 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2459 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2460 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3468 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-3468 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3468-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2461 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2462 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2463 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2464 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2465 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2466 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2467 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2468 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2469 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2470 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2471 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2472 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3596 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-3596 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3596-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2473 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2474 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2475 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2476 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2477 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2478 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2479 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2480 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2481 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2482 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2483 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2484 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3724 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-3724 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3724-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2485 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2486 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2487 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2488 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2489 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2490 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2491 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2492 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2493 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2494 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2495 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2496 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3852 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-3852 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3852-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2497 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2498 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2499 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2500 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2501 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2502 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2503 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2504 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2505 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2506 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2507 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2508 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-3980 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-3980 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=3980-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2509 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2510 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2511 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2512 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2513 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2514 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2515 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2516 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2517 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2518 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2519 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2520 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4108 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-4108 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4108-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2521 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2522 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2523 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2524 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2525 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2526 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2527 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2528 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2529 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2530 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2531 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2532 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4236 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-4236 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4236-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2533 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2534 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2535 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2536 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2537 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2538 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2539 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2540 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2541 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2542 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2543 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2544 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4364 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-4364 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4364-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2545 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2546 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2547 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2548 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2549 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2550 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2551 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2552 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2553 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2554 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2555 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2556 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4492 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-4492 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4492-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2557 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2558 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2559 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2560 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2561 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2562 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2563 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2564 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2565 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2566 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2567 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2568 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4620 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-4620 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4620-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2569 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2570 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2571 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2572 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2573 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2574 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2575 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2576 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2577 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2578 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2579 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2580 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4748 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-4748 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4748-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2581 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2582 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2583 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2584 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2585 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2586 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2587 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2588 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2589 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2590 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2591 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2592 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-4876 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-4876 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=4876-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2593 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2594 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2595 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2596 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2597 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2598 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2599 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2600 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2601 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2602 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2603 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2604 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5004 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-5004 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5004-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2605 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2606 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2607 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2608 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2609 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2610 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2611 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2612 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2613 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2614 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2615 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2616 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5132 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-5132 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5132-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2617 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2618 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2619 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2620 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2621 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2622 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2623 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2624 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2625 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2626 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2627 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2628 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5260 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-5260 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5260-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2629 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2630 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2631 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2632 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2633 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2634 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2635 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2636 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2637 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2638 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2639 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2640 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5388 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-5388 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5388-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2641 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2642 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2643 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2644 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2645 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2646 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2647 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2648 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2649 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2650 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2651 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2652 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5516 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-5516 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5516-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2653 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2654 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2655 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2656 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2657 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2658 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2659 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2660 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2661 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2662 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2663 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2664 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5644 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-5644 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5644-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2665 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2666 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2667 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2668 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2669 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2670 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2671 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2672 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2673 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2674 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2675 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2676 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5772 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-5772 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5772-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2677 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2678 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2679 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2680 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2681 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2682 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2683 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2684 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2685 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2686 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2687 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2688 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-5900 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-5900 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=5900-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2689 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2690 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2691 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2692 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2693 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2694 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2695 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2696 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2697 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2698 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2699 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2700 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6028 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-6028 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6028-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2701 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2702 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2703 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2704 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2705 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2706 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2707 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2708 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2709 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2710 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2711 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2712 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6156 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-6156 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6156-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2713 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2714 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2715 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2716 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2717 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2718 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2719 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2720 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2721 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2722 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2723 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2724 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6284 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-6284 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6284-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2725 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2726 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2727 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2728 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2729 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2730 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2731 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2732 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2733 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2734 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2735 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2736 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6412 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-6412 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6412-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2737 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2738 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2739 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2740 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2741 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2742 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2743 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2744 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2745 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2746 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2747 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2748 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6540 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-6540 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6540-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2749 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2750 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2751 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2752 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2753 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2754 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2755 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2756 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2757 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2758 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2759 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2760 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6668 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-6668 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6668-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2761 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2762 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2763 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2764 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2765 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2766 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2767 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2768 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2769 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2770 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2771 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2772 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6796 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-6796 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6796-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2773 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2774 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2775 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2776 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2777 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2778 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2779 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2780 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2781 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2782 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2783 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2784 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-6924 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-6924 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=6924-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2785 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2786 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2787 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2788 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2789 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2790 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2791 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2792 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2793 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2794 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2795 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2796 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7052 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-7052 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7052-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2797 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2798 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2799 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2800 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2801 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2802 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2803 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2804 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2805 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2806 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2807 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2808 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7180 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-7180 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7180-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2809 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2810 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2811 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2812 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2813 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2814 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2815 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2816 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2817 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2818 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2819 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2820 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7308 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-7308 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7308-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2821 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2822 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2823 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2824 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2825 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2826 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2827 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2828 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2829 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2830 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2831 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2832 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7436 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-7436 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7436-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2833 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2834 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2835 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2836 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2837 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2838 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2839 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2840 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2841 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2842 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2843 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2844 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7564 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-7564 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7564-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2845 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2846 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2847 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2848 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2849 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2850 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2851 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2852 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2853 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2854 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2855 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2856 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7692 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-7692 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7692-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2857 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2858 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2859 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2860 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2861 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2862 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2863 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2864 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2865 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2866 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2867 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2868 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7820 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-7820 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7820-dataset=textbookqa.log 2>&1
test $SGE_TASK_ID -eq 2869 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/hotpotqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=hotpotqa/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=hotpotqa.log 2>&1
test $SGE_TASK_ID -eq 2870 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/naturalquestions_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=naturalquestions/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=naturalquestions.log 2>&1
test $SGE_TASK_ID -eq 2871 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/newsqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=newsqa/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=newsqa.log 2>&1
test $SGE_TASK_ID -eq 2872 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/searchqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=searchqa/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=searchqa.log 2>&1
test $SGE_TASK_ID -eq 2873 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/squad_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=squad/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=squad.log 2>&1
test $SGE_TASK_ID -eq 2874 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/dev/triviaqa_dev_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=triviaqa/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=triviaqa.log 2>&1
test $SGE_TASK_ID -eq 2875 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/bioasq_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=bioasq/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=bioasq.log 2>&1
test $SGE_TASK_ID -eq 2876 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/drop_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=drop/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=drop.log 2>&1
test $SGE_TASK_ID -eq 2877 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/duorc_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=duorc/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=duorc.log 2>&1
test $SGE_TASK_ID -eq 2878 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/race_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=race/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=race.log 2>&1
test $SGE_TASK_ID -eq 2879 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/relationextraction_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=relationextraction/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=relationextraction.log 2>&1
test $SGE_TASK_ID -eq 2880 && sleep 10 && python src/models/run_qa.py --model_name_or_path /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29/checkpoint-7948 --do_predict --test_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/mrqa/test/textbookqa_test_squad_format.json --per_device_eval_batch_size 64 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-dataset=textbookqa/checkpoint-7948 --overwrite_output_dir --overwrite_cache --report_to none > logs/predictions/albert-xlarge-v2-mrqa-wu=100-lr=3e5-bs=32-msl=384-seed=29-checkpoint=7948-dataset=textbookqa.log 2>&1

date
