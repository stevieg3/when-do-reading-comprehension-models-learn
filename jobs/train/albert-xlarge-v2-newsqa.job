#!/bin/bash -l

#$ -cwd
#$ -S /bin/bash
#$ -l tmem=6G
#$ -t 1-4
#$ -l h_rt=75:00:00
#$ -o /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/array_files
#$ -e /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/array_files
#$ -l gpu=true

hostname
date

# Activate conda environment
conda activate rclearn

export LANG="en_US.utf8"
export LANGUAGE="en_US:en"
export WANDB_PROJECT="albert-xlarge-v2"
export HF_HOME=/SAN/intelsys/rclearn/cache

cd /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn


test $SGE_TASK_ID -eq 1 && sleep 10 && python src/models/run_qa.py --model_name_or_path albert-xlarge-v2 --train_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/newsqa/newsqa_train_unans.json --validation_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/newsqa/newsqa_dev_unans.json --version_2_with_negative --do_train --do_eval --per_device_train_batch_size 2 --gradient_accumulation_steps 16 --learning_rate 3e-05 --max_seq_length 384 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=27 --overwrite_output_dir --overwrite_cache --evaluation_strategy steps --save_steps_schedule 1 2 3 4 5 6 8 10 12 14 16 20 24 28 32 36 44 52 60 68 76 92 108 124 140 156 172 188 204 220 236 252 268 284 300 316 332 348 364 380 396 428 460 492 524 556 588 620 652 684 716 748 780 812 844 876 908 940 972 1004 1036 1100 1164 1228 1292 1356 1420 1484 1548 1612 1676 1804 1932 2060 2188 2316 2444 2572 2700 2828 2956 3084 3212 3340 3468 3596 3724 3852 3980 4108 4236 4364 4492 4620 4748 4876 5004 5132 5260 5388 5516 5644 5772 5900 6028 6156 6284 6412 6540 6668 6796 6924 7052 7180 7308 7436 7564 7692 7820 7948 --save_strategy steps --report_to wandb --seed 27 --run_name newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=27 --max_steps 8200 --warmup_steps 100 --fp16 True --logging_steps 1640 > logs/albert-xlarge-v2-newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=27.log 2>&1
test $SGE_TASK_ID -eq 2 && sleep 10 && python src/models/run_qa.py --model_name_or_path albert-xlarge-v2 --train_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/newsqa/newsqa_train_unans.json --validation_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/newsqa/newsqa_dev_unans.json --version_2_with_negative --do_train --do_eval --per_device_train_batch_size 2 --gradient_accumulation_steps 16 --learning_rate 3e-05 --max_seq_length 384 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=28 --overwrite_output_dir --overwrite_cache --evaluation_strategy steps --save_steps_schedule 1 2 3 4 5 6 8 10 12 14 16 20 24 28 32 36 44 52 60 68 76 92 108 124 140 156 172 188 204 220 236 252 268 284 300 316 332 348 364 380 396 428 460 492 524 556 588 620 652 684 716 748 780 812 844 876 908 940 972 1004 1036 1100 1164 1228 1292 1356 1420 1484 1548 1612 1676 1804 1932 2060 2188 2316 2444 2572 2700 2828 2956 3084 3212 3340 3468 3596 3724 3852 3980 4108 4236 4364 4492 4620 4748 4876 5004 5132 5260 5388 5516 5644 5772 5900 6028 6156 6284 6412 6540 6668 6796 6924 7052 7180 7308 7436 7564 7692 7820 7948 --save_strategy steps --report_to wandb --seed 28 --run_name newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=28 --max_steps 8200 --warmup_steps 100 --fp16 True --logging_steps 1640 > logs/albert-xlarge-v2-newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=28.log 2>&1
test $SGE_TASK_ID -eq 3 && sleep 10 && python src/models/run_qa.py --model_name_or_path albert-xlarge-v2 --train_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/newsqa/newsqa_train_unans.json --validation_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/newsqa/newsqa_dev_unans.json --version_2_with_negative --do_train --do_eval --per_device_train_batch_size 2 --gradient_accumulation_steps 16 --learning_rate 3e-05 --max_seq_length 384 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=29 --overwrite_output_dir --overwrite_cache --evaluation_strategy steps --save_steps_schedule 1 2 3 4 5 6 8 10 12 14 16 20 24 28 32 36 44 52 60 68 76 92 108 124 140 156 172 188 204 220 236 252 268 284 300 316 332 348 364 380 396 428 460 492 524 556 588 620 652 684 716 748 780 812 844 876 908 940 972 1004 1036 1100 1164 1228 1292 1356 1420 1484 1548 1612 1676 1804 1932 2060 2188 2316 2444 2572 2700 2828 2956 3084 3212 3340 3468 3596 3724 3852 3980 4108 4236 4364 4492 4620 4748 4876 5004 5132 5260 5388 5516 5644 5772 5900 6028 6156 6284 6412 6540 6668 6796 6924 7052 7180 7308 7436 7564 7692 7820 7948 --save_strategy steps --report_to wandb --seed 29 --run_name newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=29 --max_steps 8200 --warmup_steps 100 --fp16 True --logging_steps 1640 > logs/albert-xlarge-v2-newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=29.log 2>&1
test $SGE_TASK_ID -eq 4 && sleep 10 && python src/models/run_qa.py --model_name_or_path albert-xlarge-v2 --train_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/newsqa/newsqa_train_unans.json --validation_file /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/data/external/newsqa/newsqa_dev_unans.json --version_2_with_negative --do_train --do_eval --per_device_train_batch_size 2 --gradient_accumulation_steps 16 --learning_rate 3e-05 --max_seq_length 384 --output_dir /SAN/intelsys/rclearn/when-do-reading-comprehension-models-learn/models/albert-xlarge-v2-newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=30 --overwrite_output_dir --overwrite_cache --evaluation_strategy steps --save_steps_schedule 1 2 3 4 5 6 8 10 12 14 16 20 24 28 32 36 44 52 60 68 76 92 108 124 140 156 172 188 204 220 236 252 268 284 300 316 332 348 364 380 396 428 460 492 524 556 588 620 652 684 716 748 780 812 844 876 908 940 972 1004 1036 1100 1164 1228 1292 1356 1420 1484 1548 1612 1676 1804 1932 2060 2188 2316 2444 2572 2700 2828 2956 3084 3212 3340 3468 3596 3724 3852 3980 4108 4236 4364 4492 4620 4748 4876 5004 5132 5260 5388 5516 5644 5772 5900 6028 6156 6284 6412 6540 6668 6796 6924 7052 7180 7308 7436 7564 7692 7820 7948 --save_strategy steps --report_to wandb --seed 30 --run_name newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=30 --max_steps 8200 --warmup_steps 100 --fp16 True --logging_steps 1640 > logs/albert-xlarge-v2-newsqa-wu=100-lr=3e5-bs=32-msl=384-seed=30.log 2>&1

date
